@book{manning2008ir,
  title     = {Introduction to Information Retrieval},
  author    = {Manning, Christopher D. and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  year      = {2008},
  publisher = {Cambridge University Press}
}

@article{malkov2018hnsw,
  title   = {Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs},
  author  = {Malkov, Yu. A. and Yashunin, D. A.},
  journal = {arXiv preprint arXiv:1603.09320},
  year    = {2018}
}

@inproceedings{reimers2019sentencebert,
  title     = {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author    = {Reimers, Nils and Gurevych, Iryna},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP-IJCNLP)},
  year      = {2019}
}

@inproceedings{cer2018use,
  title     = {Universal Sentence Encoder},
  author    = {Cer, Daniel and Yang, Yinfei and Kong, Sheng-yi and Hua, Nan and Limtiaco, Nicole and St. John, Rhomni and Constant, Noah and Guajardo-C{\'e}spedes, Mario and Yuan, Steve and Tar, Chris and Strope, Brian and Kurzweil, Ray},
  booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  year      = {2018}
}

@article{sanh2019distilbert,
  title   = {DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author  = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal = {arXiv preprint arXiv:1910.01108},
  year    = {2019}
}

@article{wang2020minilm,
  title   = {MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers},
  author  = {Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
  journal = {arXiv preprint arXiv:2002.10957},
  year    = {2020}
}

@article{wang2022e5,
  title   = {Text Embeddings by Weakly-Supervised Contrastive Pre-training},
  author  = {Wang, Liang and others},
  journal = {arXiv preprint arXiv:2212.03533},
  year    = {2022}
}

@inproceedings{wolf2020transformers,
  title     = {Transformers: State-of-the-Art Natural Language Processing},
  author    = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Cl{\'e}ment and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  year      = {2020}
}

@inproceedings{conneau2020xlmr,
  title     = {Unsupervised Cross-lingual Representation Learning at Scale},
  author    = {Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, {\'E}douard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  year      = {2020}
}

@inproceedings{liu2020mbart,
  title     = {Multilingual Denoising Pre-training for Neural Machine Translation},
  author    = {Liu, Yinhan and Gu, Jiatao and Goyal, Naman and Li, Xian and Edunov, Sergey and Ghazvininejad, Marjan and Lewis, Mike and Zettlemoyer, Luke},
  booktitle = {Transactions of the Association for Computational Linguistics},
  year      = {2020}
}

@misc{xenovaTransformersJs,
  title        = {Transformers.js: State-of-the-art Machine Learning for the Web},
  author       = {Xenova},
  howpublished = {\url{https://github.com/xenova/transformers.js}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{qdrant,
  title        = {Qdrant: Vector Database for the Next Generation of AI Applications},
  author       = {{Qdrant Team}},
  howpublished = {\url{https://qdrant.tech/documentation/}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{xenovaDistiluse,
  title        = {Xenova/distiluse-base-multilingual-cased-v2 (model card)},
  author       = {{Hugging Face Contributors}},
  howpublished = {\url{https://huggingface.co/Xenova/distiluse-base-multilingual-cased-v2}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{xenovaE5Small,
  title        = {Xenova/multilingual-e5-small (model card)},
  author       = {{Hugging Face Contributors}},
  howpublished = {\url{https://huggingface.co/Xenova/multilingual-e5-small}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{xenovaMiniLM,
  title        = {Xenova/paraphrase-multilingual-MiniLM-L12-v2 (model card)},
  author       = {{Hugging Face Contributors}},
  howpublished = {\url{https://huggingface.co/Xenova/paraphrase-multilingual-MiniLM-L12-v2}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{sagunraiMbartFinetuned,
  title        = {sagunrai/mbart-large-50-nepali-finetuned-1 (model card)},
  author       = {{Hugging Face Contributors}},
  howpublished = {\url{https://huggingface.co/sagunrai/mbart-large-50-nepali-finetuned-1}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{sanjeevNepaliSummDataset,
  title        = {sanjeev-bhandari01/nepali-summarization-dataset (dataset card)},
  author       = {{Hugging Face Contributors}},
  howpublished = {\url{https://huggingface.co/datasets/sanjeev-bhandari01/nepali-summarization-dataset}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{ashokNepaliEnglishTranslation,
  title        = {ashokpoudel/nepali-english-translation-dataset (dataset card)},
  author       = {{Hugging Face Contributors}},
  howpublished = {\url{https://huggingface.co/datasets/ashokpoudel/nepali-english-translation-dataset}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{oyaNepBERT,
  title        = {oya163/NepBERT (model card)},
  author       = {{Hugging Face Contributors}},
  howpublished = {\url{https://huggingface.co/oya163/NepBERT}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{suyogyartNp20ng,
  title        = {Suyogyart/np20ng (dataset card)},
  author       = {{Hugging Face Contributors}},
  howpublished = {\url{https://huggingface.co/datasets/Suyogyart/np20ng}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@misc{kaggleNepaliSentiment,
  title        = {Nepali News Sentiment Dataset (Kaggle)},
  author       = {{Kaggle Community}},
  howpublished = {\url{https://www.kaggle.com/}},
  year         = {2025},
  note         = {Dataset referenced in notebook: \texttt{nepali\_news\_sentiment.csv}. Accessed: 2026-01-24}
}

@misc{gradio,
  title        = {Gradio: Build Machine Learning Web Apps},
  author       = {{Gradio Team}},
  howpublished = {\url{https://www.gradio.app/}},
  year         = {2025},
  note         = {Accessed: 2026-01-24}
}

@inproceedings{devlin2019bert,
  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},
  year      = {2019}
}

@inproceedings{mihalcea2004textrank,
  title     = {TextRank: Bringing Order into Texts},
  author    = {Mihalcea, Rada and Tarau, Paul},
  booktitle = {Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2004}
}

@inproceedings{lewis2020bart,
  title     = {BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author    = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year      = {2020}
}
